

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>A Mobile Structured Light System for 3D Face Acquisition - Marcoâ€™s website</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Marco's website">
<meta property="og:title" content="A Mobile Structured Light System for 3D Face Acquisition">


  <link rel="canonical" href="http://localhost:4000/portfolio/2014-06-05-3D_face/">
  <meta property="og:url" content="http://localhost:4000/portfolio/2014-06-05-3D_face/">



  <meta property="og:description" content="An interesting project to develop a portable high definition 3D face scanner">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2014-06-05T00:00:00-04:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Marco Piccirilli",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Marco's website Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">

<!-- end custom head snippets -->

    
      <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'], ['\(', '\)'] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true,
    }
  });
</script>
<script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

    
  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Marco's website</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/portfolio/">Portfolio</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/year-archive/">Blog Posts</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/cv/">CV</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/profile.png" class="author__avatar" alt="Marco Piccirilli">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Marco Piccirilli</h3>
    <p class="author__bio">PhD candidate @WVU</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Morgantown WV</li>
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> GRA @LCSEE</li>
      
      
      
      
      
        <li><a href="https://twitter.com/replacethistwitterhandle"><i class="fa fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
      
      
      
      
        <li><a href="https://www.linkedin.com/in/marco-piccirilli-b406b719"><i class="fa fa-fw fa-linkedin-square" aria-hidden="true"></i> LinkedIn</a></li>
      
      
      
      
      
      
        <li><a href="https://github.com/mpicci"><i class="fa fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="A Mobile Structured Light System for 3D Face Acquisition">
    <meta itemprop="description" content="An interesting project to develop a portable high definition 3D face scanner">
    <meta itemprop="datePublished" content="June 05, 2014">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">A Mobile Structured Light System for 3D Face Acquisition
</h1>
          
        
        
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2014-06-05T00:00:00-04:00">June 05, 2014</time></p>
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <h1 id="about-the-project">About the project</h1>

<blockquote>
  <p>Writing in Progress!!!</p>
</blockquote>

<p>In late 2012 I was asked to design a portable system able to scan human faces for border control.
At that time The Microsoft Kinect was dominating the field of the 3D acquisition devices, and in a very short time they sold more than 2 million devices.
Unfortunately Microsoft Kinect v1/v2 is not that friendly for very mobile applications, and more portable solutions, like project Tango, or sensor io were still in a sperimental stage.
After 5 years the scene is totally different, with <a href="https://all3dp.com/1/best-3d-scanner-diy-handheld-app-software/">dozen of devices available</a>.
We were able to design an active stereo system composed of a mid-range smartphone, and a pico-projector, driven by an Android App that we wrote for the acquisition and 3D reconstruction.
In Spring 2013 The <a href="https://citer.clarkson.edu/">CiTer</a> approved our project with a grant, and we deliver the outcomes in Spring 2014 at the CiTer Spring meeting at SUNY BUffalo (NY).
In that occasion we made a short demo about the device.
In 2016 our work was published on the <a href="http://ieeexplore.ieee.org/document/7361976/">IEEE Sensor Journal</a>.</p>

<hr />

<h1 id="hardware-design">Hardware Design</h1>
<p>Since the device was targeted for biometric, in particular border control, portability, battery powered, speed, and accuracy were the driven factors.
For these reasons we excluded techniques based on multi views stereo that were giving good results on static objects <a href="https://cvg.ethz.ch/mobile/LiveMetric3DReconstructionICCV2013.pdf">ICCV13</a>. 
We decided to use active scanning techniques, based on the illumination of the subject with structured light. Pretty well known are the work of <a href="http://mesh.brown.edu/">Taubin</a> at Brown University, and <a href="https://engineering.purdue.edu/ME/People/ptProfile?resource_id=117610">Song Zhang</a> at Purdue.
However, if the smartphones camera were good enough, the main problem was to find a compact and portable light source.
Fortunately, a new kind of devices were starting to be available at reasonable price, and battery powered: the <a href="http://www.projectorreviews.com/projector-categories/pico-pocket-projectors/">nano, pico, and micro projectors</a>.
For our complete setup we decided to use an Android smartphone: a mid-range device <a href="https://en.wikipedia.org/wiki/Nexus_4">Nexus 4</a> with Android <a href="https://en.wikipedia.org/wiki/Android_Jelly_Bean">JellyBean</a>. Till Android Lollipop almost all the smartphone were capable to output the video signal from the charging port. After, with the advent of google chromecast they decided to exclude the video output, and now only a few devices can be connected through HDMI port.
However, right now there are smartphones and tablets with <a href="http://www.laptopmag.com/articles/lenovo-yoga-tab3-pro">included pico projectors</a>.
Our prototype in figure was composed of the Nexus 4, fixed to the micro-projector by a common car holder, and connected via HDMI cable. Since the light from the micro projector can be too bright for the eye we decided to use an additional tele lens to avoid to be too close to the subject.
<img src="/images/100_4116_scaled.JPG" /></p>

<h1 id="active-stereo-reconstruction">Active Stereo reconstruction</h1>
<p>The pico projector and the smartphone constitute an <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwie1fHCqv_TAhXJYyYKHd7xBNQQFgg0MAE&amp;url=http%3A%2F%2Fcvgl.stanford.edu%2Fteaching%2Fcs231a_winter1415%2Flecture%2Flecture8_volumetric_stereo_notes.pdf&amp;usg=AFQjCNEQpGouAd7Szixwk-Io_kU6m4BwJg&amp;sig2=auoQR3C1h_33Zb6rGFNNgg">active stereo</a> system, where, the pico projector substitute one of the camera in the stereo configuration.
This configuration permits to use the basic stereo formulation, but itâ€™s more robust since less affected by the external light, serious problem for the stereo matching reconstruction. As will see later, using fringe pattern with active stereo configuration, speed up the scan, then the 3D reconstruction.
This solution, used by the majority of high precision 3D scanners present some downsides. The principal is the calibration procedure of the system.</p>

<h2 id="calibration">Calibration</h2>
<p>The <a href="https://boofcv.org/index.php?title=Tutorial_Camera_Calibration">calibration</a> of a camera lens is a very important step in 3D reconstruction, since other than the estimated ratio between the real and represented object, the lens introduce different distortions, making the reconstruction not accurate. With the calibration procedure we measure all the intrinsic and extrinsic quantities of the camera system, correcting distortions, and increasing the accuracy of the measures.
Traditional monocular optics can be easily calibrated using simple <a href="http://www.vision.caltech.edu/bouguetj/calib_doc/">algorithms</a> that leverage the the knowledge of a given patterns and the relative representation on the focal plane in term of pixels. Common patterns are chessboards with black and white squares, thus easy to detect corners automatically.
For a multi-views system, other than the intrinsic parameters of each lens, wwe need to measure the position, and orientation, respect to a reference, of the cameras.
In the passive stereo, this is possible repeating the calibration procedure for each camera, then with the <strong>stereo registration</strong> of the two acquired images is possible to compute the extrinsic, and parallax parameters.
In active stereo setup this procedure is quite hard, since the projector cannot " see " the pattern! The trick is to calibrate the camera first, then project the pattern with the projector and use the camera as a proxy. We refer to <a href="http://ieeexplore.ieee.org/document/6375029/">Moreno et. al.</a> for a more extensive explanation and other references.</p>

<h1 id="three-phase-structured-light">Three Phase Structured Light</h1>
<p>When I started to study structured light for 3D active acquisition devices I was literally astonished to find so many parallel, and the same math  I was using a few years before in electrical communication. The same principle used in radar, sonar, and communication, is to transmit information <code class="highlighter-rouge">shape</code> from the source: <code class="highlighter-rouge">object to scan</code> to the receiver, the <code class="highlighter-rouge">camera</code>.<br />
However, the object per se do not emit any information. What the human eye, or a camera see is the appearance, something that is difficult to describe.
Philosopher, neuroscientists, and also computer scientist have often discussed about it, and itâ€™s still an hot topic.</p>

<p>To retrieve the shape <em>information</em> we have to <em>sense</em> the object. The information to acquire is in the form of x,y,z coordinate. Illuminating the subject with a light source, and receiving the distorted light with the camera is an analogous to radar, and sonar systems.
The difference is the frequency of the electromagnetic radiation used. Hundred, or thousand of MegaHertz in the case of the radar, 100 millions of Mhz for the visible light.<br />
With different operating frequencies, although the same basic formulation, different noise and nuisances are playing a major role in the system performance.</p>

<p>There have been many structured light works using different patterns. A primitive, but simple and thoughtful is the work of <a href="http://www.vision.caltech.edu/bouguetj/ICCV98/">Bouguet and Perona</a>. They use a simple desk lamp, and by the object shadow is possible to reconstruct the shape.<br />
However, the speed of the system is restricted by the camera frame rate, and the stick speed to create the shadow.
An extension to this principle is the use of more complex <em>structured</em> patterns. The literature is vast, and is quite hard to keep track of all the little contributions.</p>

<p>The three main typologies are:</p>
<ul>
  <li>binary coded light striping</li>
  <li>gray/color coded light striping</li>
  <li>phase Shifting.</li>
</ul>

<p>The main difference regard the way the shape information is encoded.
A more thorough explanation can be found <a href="http://www.sci.utah.edu/~gerig/CS6320-S2012/Materials/CS6320-CV-S2012-StructuredLight.pdf">here</a>.</p>

<p><img src="/images/Binary_coding.jpg" /></p>

<p>The first two techniques code the amplitude of the pattern light with discrete values. A set of patterns are successively projected onto the measuring
surface, codeword for a given pixel is formed by a sequence of patterns.
The main problem with this techniques is that the number of patterns is limited by the codeword length. Gray code can be used for robustness: adjacent stripes must only differ in 1 bit. However these techniques, used in old scanners, make the system slow, and especially are not resilient to external illumination, because the information is coded in the white or black level of the light.</p>

<p>A more interesting technique, introduced by <a href="http://www.ifp.uni-stuttgart.de/publications/2001/Videometrics01-Guehring-4309-24.pdf">Guehring et al</a>
is the phase-shift PS method. The PS method projects a sequence of periodic intensity patterns, each of which is offset by a fraction of its period from the previous one, so that the entire period is covered. As a result, one obtains a so-called relative phase map, which is also of a periodic nature: values readily available from the relative <em>wrapped</em> phase map are said to be wrapped in the range modulo <script type="math/tex">2 \pi</script>.<br />
The PS method typically assumes a projection of periodic sinusoidal patterns several times, where a periodic sine pattern is shifted between projections. A periodic pattern is actually shifted N   times by an amount of <script type="math/tex">\phi_i</script>, where shifts are equally distributed to cover the entire period:</p>

<script type="math/tex; mode=display">\phi_i = \frac{2 \pi}{N} \cdot i \qquad i= 0,1,\dots,N-1</script>

<p>For a camera image pixel, the detected gray-level intensity, <script type="math/tex">g(x,y)</script> at <script type="math/tex">(x,y)</script> position, obtained as a result of a projected periodic pattern in context and for a shift i can be modeled as:</p>

<script type="math/tex; mode=display">g(x,y) = a(x,y) + b(x,y) \cdot \cos(2 \pi f_0 x + \phi_i(x,y))</script>

<p>where, <script type="math/tex">a(x,y)</script> is the background intensity, <script type="math/tex">b(x,y)</script> is the amplitude modulation of fringes, <script type="math/tex">f_0</script> is the spatial carrier frequency, <script type="math/tex">\phi_i(x,y)</script>is the phase modulation of fringes.</p>

<h2 id="in-electrical-communications">In Electrical Communications</h2>
<p>The above equation is very common in electrical communications! Itâ€™s the basic formulation used in <a href="https://en.wikibooks.org/wiki/Communication_Systems/What_is_Modulation%3F">modulation theory</a>.
In particular, the above form is called phase modulation, or angle modulation. This type of modulation is very interesting, since encode the information on phase variations.
Common distortions of the electrical signal on means like coaxial cables, fiber optics, or ether are principally associated with the amplitude, encoding the information on the phase makes the system more resilient to noise. 
Moreover, since <script type="math/tex">\phi_i</script> is discrete, the phase variations are discrete too. In electrical communications this modulation is called <a href="https://en.wikipedia.org/wiki/Phase-shift_keying">PSK: phase shift keying</a>, used commonly to transmit digital signals.</p>

<p>My experience</p>

<p>As <a href="https://en.wikipedia.org/wiki/Amateur_radio">Ham Radio</a> operator I used many many times the PSK for packet transmission. In early 2000 was able to meet and experimenting high speed packet transmission in Northern Italy and Slovenia where Matiaz Vidmar developed a BPSK radio at 2400 MHz.</p>

<h2 id="recover-the-relative-phase">Recover the relative phase</h2>
<p>Phase-shifting methods are extensively employed in optical metrology, especially with the development of digital computers and digital display technologies. A well known algorithm use just <a href="https://www.osapublishing.org/ao/abstract.cfm?uri=ao-45-21-5086">three phase shift</a>. 
Three-step phase-shifting algorithm have the advantage of fast measurement because they require the minimum number of fringe images to reconstruct one 3D shape. Each shift has a variation of <script type="math/tex">2\pi/3</script>. The correspondent intensities of fringe images are:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
g_1(x,y) &= a(x,y) + b(x,y) \cdot \cos(2 \pi f_0 x + -2\pi/3)\\\
g_2(x,y) &= a(x,y) + b(x,y) \cdot \cos(2 \pi f_0 x)\\
g_3(x,y) &= a(x,y) + b(x,y) \cdot \cos(2 \pi f_0 x + 2\pi/3)\\
\end{align*} %]]></script>

<p>To recover the realtive phase there is a closed form solution:</p>

<script type="math/tex; mode=display">\phi_R(x,y) = \arctan(\sqrt{3} \frac{g_1(x,y) - g_3(x,y)}{2g_2(x,y)-g_1(x,y)-g_3(x,y)})</script>

<h2 id="unwrapping">Unwrapping</h2>
<p>Due to the periodic nature of a given periodic pattern, <script type="math/tex">\phi_R(x,y)</script> value by itself is not a unique representative that we can use to solve the correspondence problem between the image pixels of two or more cameras, i.e., between a single camera and the source of projection (e.g. a common video projector).
The phase <script type="math/tex">\phi_R(x,y)</script> is called modulo <script type="math/tex">2\pi</script> at each pixel. If the fringe patterns contain multiple fringes, as often is the case, <a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-0471249351.html">phase unwrapping</a> is necessary to remove the sawtooth-like discontinuities and obtain a continuous phase map.</p>

<p>A pattern period can be defined either directly by the number of requested periods that pattern must have, or by the length of a single period, bearing in mind the total available pattern width in the context. For simplicity of explanation, we can start by representing our approach by considering two periodic sine patterns, defined by integer length periods <script type="math/tex">\lambda_1</script> and <script type="math/tex">\lambda_2</script>.
<img src="/images/Unwrap.jpg" /> Figure shows the appearance of two sine patterns: each pattern column has an intensity according to the sine value of its position on the abscissa axis, and the propagation of the absolute phase axis along the width of the pattern. A pair of relative phases <script type="math/tex">(\phi_{R,1}</script>, <script type="math/tex">\phi_{R,2})</script> is indicated for the arbitrary absolute phase value Ð¤ABS and the following equations hold:</p>

<p>SS\phi_{ABS} = k_1 \lambda_1 + \phi_{R,1} = k_2 \lambda_2 +\phi_{R,2}</p>

<p>However, this method assume multiple patterns, and multiple acquisitions with different frequencies. Unfortunately, this could be a important downside
due to the low frame rate of the mobile device.
In this project we considered different <em>unwrapping</em> techniques, but we used the one with good trade-off</p>

<!--------------------------------------------------------------------------------->
<!-- $$                                                                          -->
<!-- \begin{align*}                                                              -->
<!--   & \phi(x,y) = \phi \left(\sum_{i=1}^n x_ie_i, \sum_{j=1}^n y_je_j \right) -->
<!--   = \sum_{i=1}^n \sum_{j=1}^n x_i y_j \phi(e_i, e_j) = \\                   -->
<!--   & (x_1, \ldots, x_n) \left( \begin{array}{ccc}                            -->
<!--       \phi(e_1, e_1) & \cdots & \phi(e_1, e_n) \\                           -->
<!--       \vdots & \ddots & \vdots \\                                           -->
<!--       \phi(e_n, e_1) & \cdots & \phi(e_n, e_n)                              -->
<!--     \end{array} \right)                                                     -->
<!--   \left( \begin{array}{c}                                                   -->
<!--       y_1 \\                                                                -->
<!--       \vdots \\                                                             -->
<!--       y_n                                                                   -->
<!--     \end{array} \right)                                                     -->
<!-- \end{align*}                                                                -->
<!-- $$                                                                          -->
<!--------------------------------------------------------------------------------->

<h1 id="android-sdk-ndk-openframework">Android SDK, NDK, OpenFramework</h1>

<p><img src="/images/Screenshot_2014-05-01-18-14-13.png" /></p>

<p><img src="/images/Screenshot_2014-05-02-15-36-23_H.png" /></p>

<p><img src="/images/Screenshot_2014-05-02-18-24-06.png" /></p>

        
      </section>

      <footer class="page__meta">
        
        




      </footer>

      

<section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/portfolio/2014-06-05-3D_face/" class="btn btn--twitter" title="Share on Twitter"><i class="fa fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/portfolio/2014-06-05-3D_face/" class="btn btn--facebook" title="Share on Facebook"><i class="fa fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://plus.google.com/share?url=http://localhost:4000/portfolio/2014-06-05-3D_face/" class="btn btn--google-plus" title="Share on Google Plus"><i class="fa fa-fw fa-google-plus" aria-hidden="true"></i><span> Google+</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/portfolio/2014-06-05-3D_face/" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fa fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>

      


  <nav class="pagination">
    
      <a href="http://localhost:4000/portfolio/2013-06-06-BSA/" class="pagination--pager" title="A framework to study the Human Body Surface Area
">Previous</a>
    
    
      <a href="http://localhost:4000/portfolio/2016-09-09-Speaker-recognition/" class="pagination--pager" title="Speaker verification system with a siamese network
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    </script>

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/mpicci"><i class="fa fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2017 Marco Piccirilli. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

