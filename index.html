<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8">
  <title>Marco Piccirilli</title>

  <meta name="author" content="Marco Piccirilli" />
  <meta name="description" content="" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <link rel="alternate" type="application/rss+xml" href="/atom.xml" />

  <link href="/vendor/css/bootstrap.min.css" rel="stylesheet">
  <link href="/vendor/css/font-awesome.min.css" rel="stylesheet">
  <link href="/vendor/css/academicons.min.css" rel="stylesheet">
  <link href="/vendor/pygments/default.css" rel="stylesheet">
  <link href="/css/bamos.css" rel="stylesheet">
  <link href="/css/sharingbuttons.css" rel="stylesheet">

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
	<div class="navbar navbar-default navbar-fixed-top">
		<div class="container">
			<div class="row">
				<div class="col-md-10 col-md-offset-1">
					<div class="navbar-header">
						  <a href="/" class="navbar-brand">
                  <div>
                      <img src="/images/marco.jpg" class="img-circle"></img>
                      Marco Piccirilli
                  </div>
              </a>
						<button class="navbar-toggle" type="button" data-toggle="collapse"
                    data-target="#navbar-main">
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
							<span class="icon-bar"></span>
						</button>
					</div>
					<div class="navbar-collapse collapse" id="navbar-main">
						<ul class="nav navbar-nav">
							<li>
								<a href="/">About</a>
							</li>
							<li>
								<a href="/blog/">Blog</a>
							</li>
						</ul>
						<ul class="nav navbar-nav navbar-right" style="font-size: 1.5em">
							<li>
								<a href="http://github.com/mpicci" target="_blank">
									<i class="fa fa-lg fa-github"></i></a>
							</li>
							<li>
								<a href="http://twitter.com/piccibiker" target="_blank">
									<i class="fa fa-lg fa-twitter"></i></a>
							</li>
              <li>
                <a href="https://scholar.google.com/citations?user=o_4Mdc4AAAAJ&hl=en" target="_blank">
                  <i class="ai ai-google-scholar"></i></a>
              </li>
              <li>
                  <a href="/atom.xml" target="_blank">
                      <i class="fa fa-rss"></i></a>
              </li>
						</ul>
					</div>
				</div>
			</div>
		</div>
	</div>

  <div class="container">
  <div class="row">
    <div class="col-md-10 col-md-offset-1 vcenter idxHdr">
      <div style='font-size: 2em; color: #4582ec; font-weight: bold; padding-bottom: 0.3em;'>Marco Piccirilli</div>
      <div style='font-size: 1.2em;'>
        Ph.D.
      </div>
      <div style='font-size: 1.2em'>
        <a href="http://www.wvu.edu">Electrical Engineering</a>
      </div>
      <div style='font-size: 1.2em'>
        <a href="http://www.wvu.edu/">West Virginia University</a>
      </div>
      <div style='font-size: 1.2em'>
      D.Ing. Telecommunications
      </div>
      <div style='font-size: 1.2em'>
        <a href="https://www.dei.unipd.it/en/">University of Padova - Italy</a>
      </div>
      <br/>

      <div style="padding: 0.3em; background-color: #4582ec; display: inline-block; border-radius: 4px; font-size: 1.2em;">
        <a href="data/CV_Marco_Piccirilli.pdf" target='_blank' style='text-decoration: none;'>
          <i style='color: white' class="fa fa-download"></i>
        </a>
        <a href="data/CV_Marco_Piccirilli.pdf" target='_blank' style='text-decoration: none;'>
          <i style='color: white' class="fa fa-code-fork"></i>
        </a>
        <a href="data/CV_Marco_Piccirilli.pdf" target='_blank' style='color: white; text-decoration: none;'>CV</a>
      </div>

      <ul class="list-inline idxIcons" style='font-size: 1.9em; margin-top: 0.5em;'>
        <li>
          <a href="http://github.com/mpicci" target="_blank">
            <i class="fa fa-fw fa-github"></i></a>
        </li>
        <li>
          <a href="http://twitter.com/piccibiker" target="_blank">
            <i class="fa fa-fw fa-twitter"></i></a>
        </li>
        <li>
          <a href="https://scholar.google.com/citations?user=o_4Mdc4AAAAJ&hl=en&oi=ao" target="_blank">
          <i class="ai ai-google-scholar"></i></a>
        </li>
        <li>
          <a href="https://www.linkedin.com/in/marco-piccirilli-b406b719/" target="_blank">
            <i class="fa fa-fw fa-linkedin"></i></a>
        </li>
        
      </ul>
      <hr/>
      <strong>
          I am on the job market for an industry machine learning/ computer vision 
          research position.
      </strong>
    </div>
    
  </div>

  <div class="row">
    <div class="col-md-10 col-md-offset-1">
      <hr />

<p>I graduated with a Ph.D. in Electrical Engineering from <a href="http://www.wvu.edu">West Virginia University</a>. At WVU I worked under the supervision of <a href="http://vision.csee.wvu.edu/~doretto/">Gianfranco Doretto</a>  and <a href="http://community.wvu.edu/~daadjeroh/">Donald Adjeroh</a> on machine learning and computer vision for biometrics and biomedical applications. I am particularly interested in improving our understanding of important modeling problems in computer vision, and signal processing through the use of deep learning, optimization, theory, and statistics. 
The interest in medical imaging took me to join the newly established <a href="http://wvumedicine.org/heart/">Heart and Vascular Institute</a> and the new Cardiovascular Imaging center of innovation guided by Dr. <a href="https://directory.hsc.wvu.edu/Profile/47668">Partho Sengupta M.D.</a>.
 My most recent work is <a href="https://arxiv.org/abs/1709.10190">Domain Adaptation and Generalization</a>.</p>

<h2 id="i-classfa-fa-chevron-righti-news"><i class="fa fa-chevron-right"></i> News</h2>
<table class="table table-hover">
<tr>
  <td class="col-md-3">Dec 2018</td>
  <td>The work on Manifold Learning for Left Ventricular Diastolic Dysfunction has been accepted as moderated poster at <a href="https://accscientificsession.acc.org/">ACC 19</a>.</td>
</tr>
<tr>
  <td class="col-md-3">Oct 2018</td>
  <td>I was a volunteer at the <a href="https://wvumedicine.org/info/choice/">CHOICE</a> Heart Health screening event.</td>
</tr>

<tr>
  <td class="col-md-3">Apr 2018</td>
  <td>I started working as a researcher at <a href="http://wvumedicine.org/heart/">Heart and Vascular Institute</a>.</td>
</tr>
<tr>
  <td class="col-md-3">Dec 2017</td>
  <td>I defended successfully my dissertation on <a href="https://search.proquest.com/docview/2043000267?pq-origsite=gscholar">machine learning approaches for human body shape analysis.</a> </td>
</tr>

<tr>
  <td class="col-md-3">Oct 2017</td>
  <td>I'll be presenting our poster on <a href="https://arxiv.org/abs/1709.10190">Unified Deep Supervised Domain Adaptation and Generalization</a> at <a href="http://iccv2017.thecvf.com/">ICCV2017</a>.</td>
</tr>

<tr>
  <td class="col-md-3">Jun 2016</td>
  <td>I attended <a href="http://cvpr2016.thecvf.com/">CVPR 2016</a> in Las Vegas, NV.<br />
  We presented our work on: <a href="https://ieeexplore.ieee.org/document/7780535/">Information Bottleneck Learning Using Privileged Information for Visual Recognition</a> with my colleague <a href="http://vision.csee.wvu.edu/~motiian/">Saeid Motiian</a>.
  </td>
</tr>
<tr>
  <td class="col-md-3">May 2016</td>
  <td>I attended the <a href="http://www.engineering.pitt.edu/ieeesps/">IEEE SPS Summer School on Signal Processing and Machine Learning for Big Data, Pittsburgh, PA</a>.</td>
</tr>
<tr>
  <td class="col-md-3">July 2015</td>
  <td>I attended the <a href="http://iplab.dmi.unict.it/icvss2015/">ICVSS15</a> International Computer Vision Summer School, Sicily Italy.<br /> Organized by Roberto Cipolla, Sebastiano Battiato, and Giovanni Maria Farinella.<br />
  Mentored by Marc Pollefeys
  </td>
</tr>

<tr>
  <td class="col-md-3">Dec 2011</td>
  <td>I attended IJCB 2011 in Washington DC<br />
  We presented our work:"Can facial metrology predict gender?" with Arun Ross, T. Bourlai, and Donald Adjeroh <br />
  </td>
</tr>
<tr>
  <td class="col-md-3">Dec 2010</td>
  <td>Our work: Predictability and correlation in human metrology, with Arun Ross and Donald Adjeroh has been presented at WIFS
  </td>
</tr>
<tr>
<td class="col-md-3"><h4><a href="/news">View all news</a></h4></td>
</tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-education"><i class="fa fa-chevron-right"></i> Education</h2>

<table class="table table-hover">
  <tr>
    <td class="col-md-3">Jan 2010 - May 2018</td>
    <td>
        <strong>Ph.D. in Electrical Engineering</strong><br />
        Computer Vision, Machine Learning, Biometric.<br />
      West Virginia University<br />
      Morgantown, WV (USA)
    </td>
    <td>
        Fullfilled requirement for <br /><strong>Ms Computer Science</strong>
        <br />
      West Virginia University
    </td>
  </tr>
  <tr>
    <td class="col-md-3">       - Apr 2007</td>
    <td>
        <strong>"Laurea" Degree Telecommunication Engineering</strong>
        <br />
        Specialty: Optical Communication<br />
        Focus: Source coding, source-channel coding,<br />
        distribuited video coding.<br />
      Padua University (Italy)
    </td>
  </tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-research-experience"><i class="fa fa-chevron-right"></i> Research Experience</h2>
<table class="table table-hover">
<tr>
  <td class="col-md-3">April 2018 - Present</td>
  <td>
    <strong>Heart and Vascular Institute, School of Medicine,  West Virginia University</strong> <br />
    Researcher<br />
    Machine learning and computer vision for Cardiovascular imaging.
  </td>
</tr>
<tr>
  <td class="col-md-3">Aug 2017 - Dec 2017</td>
  <td>
    <strong>Heart and Vascular Institute, School of Medicine,  West Virginia University</strong> <br />
    Graduate Assistant.<br />
    Machine learning and computer vision for Cardiovascular imaging.
  </td>
</tr>
<tr>
  <td class="col-md-3">Jan 2010 - May 2018</td>
  <td>
    <strong>West Virginia University</strong>, Gianfranco Doretto, Donald Adjeroh <br />
    Machine learning, computer vision, biometrics
  </td>
</tr>
<tr>
  <td class="col-md-3">June 2013 - May 2014</td>
  <td>
    <strong><a href="https://citer.clarkson.edu/">Center for Identification Technology Research</a></strong>, Co-PI <br />
    Mobile Structured Light System for 3D Face Acquisition.
  </td>
</tr>
<tr>
  <td class="col-md-3"> June 2010 - May 2012</td>
  <td>
    <strong><a href="https://citer.clarkson.edu/">Center for Identification Technology Research</a></strong>, Arun Ross, Bojan Cukic <br />
    Night Biometrics project funded by ONR’s Green Devil II initiative
  </td>
</tr>
<tr>
  <td class="col-md-3">Aug 2008 - Dec 2008</td>
  <td>
    <strong>West Virginia University</strong>, Xin Li, Donald Adjeroh <br />
    Visiting Student <br />
    Segmentation of vessels structures, and macular retinopathy in retinal images.
  </td>
</tr>
<tr>
  <td class="col-md-3">Apr 2007 - Dec 2009</td>
  <td>
    <strong><a href="https://www.dei.unipd.it/en">Department of Information Engineering (DEI), Padua Univ.</a></strong>, <a href="https://www.dei.unipd.it/en/persona/BF184E84D5EDC3D1D65880C152BC077A">Giancarlo Calvagno</a><br />
    Distribuited Video Coding with Continuous-Value Syndromes,<br />
    Segmentation of vessels structures, and macular retinopathy in retinal images.
  </td>
</tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-selected-publications"><i class="fa fa-chevron-right"></i> Selected Publications</h2>
<!-- <a href="https://github.com/bamos/cv/blob/master/publications/selected.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a> -->

<p><a href="https://scholar.google.com/citations?user=o_4Mdc4AAAAJ&amp;hl=en&amp;oi=ao" class="btn btn-primary" style="padding: 0.3em;">
  <i class="ai ai-google-scholar"></i> Google Scholar
</a></p>

<table class="table table-hover">

<tr>
<td class="col-md-3"><a href="https://arxiv.org/abs/1709.10190" target="_blank"><img src="images/publications/SiameseClassification_new.png" /></a> </td>
<td>
    <strong>Unified Deep Supervised Domain Adaptation and Generalization</strong><br />
    S. Motiian, <strong>M. Piccirilli</strong>, D. A. Adjeroh, G. Doretto<br />
    ICCV 2017<br />
    
    [1] 
[<a href="javascript: none" onclick="$(&quot;#abs_CCSA&quot;).toggle()">abs</a>] [<a href="https://arxiv.org/abs/1709.10190" target="_blank">pdf</a>] [<a href="http://vision.csee.wvu.edu/~motiian/Details/CCSA.html" target="_blank">web</a>]<br />
    
<div id="abs_CCSA" style="text-align: justify; display: none">
        <p>This work provides a unified framework for addressing the problem of visual supervised domain adaptation and generalization with deep models. The main idea is to exploit the Siamese architecture to learn an embedding subspace that is discriminative, and where mapped visual domains are semantically aligned and yet maximally separated. The supervised setting becomes attractive especially when only few target data samples need to be labeled. In this scenario, alignment and separation of semantic probability distributions is difficult because of the lack of data. We found that by reverting to point-wise surrogates of distribution distances and similarities provides an effective solution. In addition, the approach has a high speed of adaptation, which requires an extremely low number of labeled target training samples, even one per category can be effective. The approach is extended to domain generalization. For both applications the experiments show very promising results.</p>
      </div>

</td>
</tr>


<tr>
<td class="col-md-3"><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0166749" target="_blank"><img src="images/publications/journal.pone.png" /></a> </td>
<td>
    <strong>A Framework for Analyzing the Whole Body Surface Area from a Single View</strong><br />
    <strong>M. Piccirilli</strong>, G. Doretto, D.A. Adjeroh <br />
    PLOS One 2017<br />
    
    [2] 
[<a href="javascript: none" onclick="$(&quot;#abs_pone&quot;).toggle()">abs</a>] [<a href="http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0166749&amp;type=printable" target="_blank">pdf</a>] [<a href="/2012/12/12/Virtual-bodies" target="_blank">blog1</a>] [<a href="2013/06/06/BSA" target="_blank">blog2</a>] <br />
    
<div id="abs_pone" style="text-align: justify; display: none">
        <p>We present a virtual reality (VR) framework for the analysis of whole human body surface area. Usual methods for determining the whole body surface area (WBSA) are based on well known formulae, characterized by large errors when the subject is obese, or belongs to certain subgroups. For these situations, we believe that a computer vision approach can overcome these problems and provide a better estimate of this important body indicator. Unfortunately, using machine learning techniques to design a computer vision system able to provide a new body indicator that goes beyond the use of only body weight and height, entails a long and expensive data acquisition process. A more viable solution is to use a dataset composed of virtual subjects. Generating a virtual dataset allowed us to build a population with different characteristics (obese, underweight, age, gender). However, synthetic data might differ from a real scenario, typical of the physician’s clinic. For this reason we develop a new virtual environment to facilitate the analysis of human subjects in 3D. This framework can simulate the acquisition process of a real camera, making it easy to analyze and to create training data for machine learning algorithms. With this virtual environment, we can easily simulate the real setup of a clinic, where a subject is standing in front of a camera, or may assume a different pose with respect to the camera. We use this newly designated environment to analyze the whole body surface area (WBSA). In particular, we show that we can obtain accurate WBSA estimations with just one view, virtually enabling the possibility to use inexpensive depth sensors (e.g., the Kinect) for large scale quantification of the WBSA from a single view 3D map.</p>
      </div>

</td>
</tr>


<tr>
<td class="col-md-3"><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Motiian_Information_Bottleneck_Learning_CVPR_2016_paper.pdf" target="_blank"><img src="images/publications/LUPI_PI.png" /></a> </td>
<td>
    <strong>Information Bottleneck Learning Using Privileged Information for Visual Recognition</strong><br />
    S. Motiian <strong>M. Piccirilli</strong> D. A. Adjeroh G. Doretto<br />
    CVPR 2016<br />
    
    [3] 
[<a href="javascript: none" onclick="$(&quot;#abs_LUPI_PI&quot;).toggle()">abs</a>] [<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Motiian_Information_Bottleneck_Learning_CVPR_2016_paper.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_LUPI_PI" style="text-align: justify; display: none">
        <p>We explore the visual recognition problem from a main
data view when an auxiliary data view is available during
training. This is important because it allows improving the
training of visual classifiers when paired additional data
is cheaply available, and it improves the recognition from
multi-view data when there is a missing view at testing time.
The problem is challenging because of the intrinsic asymmetry
caused by the missing auxiliary view during testing.
We account for such view during training by extending the
information bottleneck method, and by combining it with
risk minimization. In this way, we establish an information
theoretic principle for leaning any type of visual classifier
under this particular setting. We use this principle to design
a large-margin classifier with an efficient optimization in
the primal space. We extensively compare our method with
the state-of-the-art on different visual recognition datasets,
and with different types of auxiliary data, and show that the
proposed framework has a very promising potential.</p>
      </div>

</td>
</tr>



<tr>
<td class="col-md-3"><a href="https://www.researchgate.net/publication/287965460_A_Mobile_Structured_Light_System_for_3D_Face_Acquisition" target="_blank"><img src="images/publications/Marco_cropped.png" /></a> </td>
<td>
    <strong>A Mobile Structured Light System for 3D Face Acquisition</strong><br />
    <strong>M. Piccirilli</strong>, G. Doretto, A. Ross, D.A. Adjeroh <br />
    IEEE SENSORS JOURNAL Apr. 2016<br />
    
    [4] 
[<a href="javascript: none" onclick="$(&quot;#abs_3d_mobile&quot;).toggle()">abs</a>] [<a href="https://www.researchgate.net/publication/287965460_A_Mobile_Structured_Light_System_for_3D_Face_Acquisition" target="_blank">pdf</a>] [<a href="/2014/06/05/3D_face/" target="_blank">blog</a>] <br />
    
<div id="abs_3d_mobile" style="text-align: justify; display: none">
        <p>A mobile sensor based on fringe projection
techniques is developed with the goal of acquiring face 3D
and color with a smartphone device. The system consists of a
portable pico-projector and an Android-based smartphone. The
data acquisition, pattern generation. and reconstruction of the
final 3D point cloud are all driven by the smartphone. We present
results on the root-mean-square error (RMSE) of the sensor and
on 3D face matching.</p>
      </div>

</td>
</tr>


<tr>
<td class="col-md-3"><a href="https://ieeexplore.ieee.org/document/5711470/" target="_blank"><img src="images/publications/5711470-fig-4-source-small.gif" /></a> </td>
<td>
    <strong>Predictability and correlation in human metrology</strong><br />
    D. Adjeroh, D. Cao, <strong>M. Piccirilli</strong>, A. Ross <br />
    WIFS 2010<br />
    
    [5] 
[<a href="javascript: none" onclick="$(&quot;#abs_wifs10&quot;).toggle()">abs</a>] [<a href="https://ieeexplore.ieee.org/document/5711470/" target="_blank">pdf</a>] <br />
    
<div id="abs_wifs10" style="text-align: justify; display: none">
        <p>Human metrology provides an important soft bio-metric, which can be used in challenging situations such as human identification at a distance, when traditional biometric traits such as fingerprints or iris cannot be easily acquired. We study the problem of predictability and correlation in human metrology, using the tools of uncertainty and differential entropy. We show that while various metrological features are highly correlated with each other, there exists some correlation clusters in human metrology, whereby measurements in a cluster tend to be highly correlated with each other but not with the others. Based on these clusters, we propose a two-step approach for predicting unknown body measurements. Using the same framework, we study the problem of estimating other soft biometrics such as weight and gender.</p>
      </div>

</td>
</tr>

</table>

<h2 id="i-classfa-fa-chevron-righti-honors--awards"><i class="fa fa-chevron-right"></i> Honors &amp; Awards</h2>
<table class="table table-hover">
<tr>
  <td class="col-md-2">2014</td>
  <td>
    Finalist Innovation Award West Virginia University
    <!--  -->
  </td>
</tr>
<tr>
  <td class="col-md-2">Jan 2014</td>
  <td>
    <strong>Midsumo Challenge</strong>: Use Technology to optimize our system for measuring furniture.
    <!--  -->
  </td>
</tr>
<tr>
  <td class="col-md-2">Jun 2013 - Jun 2014</td>
  <td>
    <strong>CiTer Grant</strong>-National Science Foundation Office within the Director Industry and University Cooperative Research Program.
Project: A Mobile Structured Light System for 3D Face Acquisition.
    <!--  -->
  </td>
</tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-public-service"><i class="fa fa-chevron-right"></i> Public service</h2>
<table class="table table-hover">
<tr>
  <td>
    Reviewer: ICPRAM14, AVSS, IEEE Sensor, TPAMI, ICCV17, CVPR18, BMJ, ACCV2018
    <!--  -->
  </td>
</tr>
</table>

<h2 id="i-classfa-fa-chevron-righti-skills"><i class="fa fa-chevron-right"></i> Skills</h2>
<table class="table table-hover">
<tr>
  <td class="col-md-2">Languages</td>
  <td>
      <p>C, C++, Java, Make, MatLab, Python, R</p>
    </td>
</tr>
<tr>
  <td class="col-md-2">Frameworks</td>
  <td>
      <p>NumPy, Pandas, PyTorch, SciPy, TensorFlow, Torch7, Caffe, PCL, OpenFramework</p>
    </td>
</tr>
<tr>
  <td class="col-md-2">Systems</td>
  <td>
      <p>Linux, OSX</p>
    </td>
</tr>
</table>

<h3 id="conference-proceedings">Conference Proceedings</h3>
<!-- <a href="https://github.com/bamos/cv/blob/master/publications/conference.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a> -->

<table class="table table-hover">
<tr>
<td class="col-md-3"><a href="https://arxiv.org/abs/1709.10190" target="_blank"><img src="images/publications/SiameseClassification_new.png" /></a> </td>
<td>
    <strong>Unified Deep Supervised Domain Adaptation and Generalization</strong><br />
    S. Motiian, <strong>M. Piccirilli</strong>, D. A. Adjeroh, G. Doretto<br />
    ICCV 2017<br />
    
    [C1] 
[<a href="javascript: none" onclick="$(&quot;#abs_CCSA&quot;).toggle()">abs</a>] [<a href="https://arxiv.org/abs/1709.10190" target="_blank">pdf</a>] [<a href="http://vision.csee.wvu.edu/~motiian/Details/CCSA.html" target="_blank">web</a>]<br />
    
<div id="abs_CCSA" style="text-align: justify; display: none">
        <p>This work provides a unified framework for addressing the problem of visual supervised domain adaptation and generalization with deep models. The main idea is to exploit the Siamese architecture to learn an embedding subspace that is discriminative, and where mapped visual domains are semantically aligned and yet maximally separated. The supervised setting becomes attractive especially when only few target data samples need to be labeled. In this scenario, alignment and separation of semantic probability distributions is difficult because of the lack of data. We found that by reverting to point-wise surrogates of distribution distances and similarities provides an effective solution. In addition, the approach has a high speed of adaptation, which requires an extremely low number of labeled target training samples, even one per category can be effective. The approach is extended to domain generalization. For both applications the experiments show very promising results.</p>
      </div>

</td>
</tr>


<tr>
<td class="col-md-3"><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Motiian_Information_Bottleneck_Learning_CVPR_2016_paper.pdf" target="_blank"><img src="images/publications/LUPI_PI.png" /></a> </td>
<td>
    <strong>Information Bottleneck Learning Using Privileged Information for Visual Recognition</strong><br />
    S. Motiian <strong>M. Piccirilli</strong> D. A. Adjeroh G. Doretto<br />
    CVPR 2016<br />
    
    [C2] 
[<a href="javascript: none" onclick="$(&quot;#abs_LUPI_PI&quot;).toggle()">abs</a>] [<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Motiian_Information_Bottleneck_Learning_CVPR_2016_paper.pdf" target="_blank">pdf</a>] <br />
    
<div id="abs_LUPI_PI" style="text-align: justify; display: none">
        <p>We explore the visual recognition problem from a main
data view when an auxiliary data view is available during
training. This is important because it allows improving the
training of visual classifiers when paired additional data
is cheaply available, and it improves the recognition from
multi-view data when there is a missing view at testing time.
The problem is challenging because of the intrinsic asymmetry
caused by the missing auxiliary view during testing.
We account for such view during training by extending the
information bottleneck method, and by combining it with
risk minimization. In this way, we establish an information
theoretic principle for leaning any type of visual classifier
under this particular setting. We use this principle to design
a large-margin classifier with an efficient optimization in
the primal space. We extensively compare our method with
the state-of-the-art on different visual recognition datasets,
and with different types of auxiliary data, and show that the
proposed framework has a very promising potential.</p>
      </div>

</td>
</tr>

<tr>
<td class="col-md-3"><a href="https://ieeexplore.ieee.org/document/6117471/" target="_blank"><img src="images/publications/Deng_face.png" /></a> </td>
<td>
    <strong>"Can facial metrology predict gender?"</strong><br />
    D. Cao, C. Chen, <strong>M. Piccirilli</strong>, D. Adjeroh, T. Bourlai, and A. Ross.<br />
    IJCB<br />
    
    [C3] 
[<a href="javascript: none" onclick="$(&quot;#abs_face2011&quot;).toggle()">abs</a>] [<a href="https://ieeexplore.ieee.org/document/6117471/" target="_blank">pdf</a>] <br />
    
<div id="abs_face2011" style="text-align: justify; display: none">
        <p>We investigate the question of whether facial metrology can be exploited for reliable gender prediction. A new method based solely on metrological information from facial landmarks is developed. Here, metrological features are defined in terms of specially normalized angle and distance measures and computed based on given landmarks on facial images. The performance of the proposed metrology- based method is compared with that of a state-of-the-art appearance-based method for gender classification. Results are reported on two standard face databases, namely, MUCT and XM2VTS containing 276 and 295 images, respectively. The performance of the metrology-based approach was slightly lower than that of the appearance- based method by only about 3.8% for the MUCT database and about 5.7% for the XM2VTS database.</p>
      </div>

</td>
</tr>


<tr>
<td class="col-md-3"><a href="https://ieeexplore.ieee.org/document/5711470/" target="_blank"><img src="images/publications/5711470-fig-4-source-small.gif" /></a> </td>
<td>
    <strong>Predictability and correlation in human metrology</strong><br />
    D. Adjeroh, D. Cao, <strong>M. Piccirilli</strong>, A. Ross <br />
    WIFS 2010<br />
    
    [C4] 
[<a href="javascript: none" onclick="$(&quot;#abs_wifs10&quot;).toggle()">abs</a>] [<a href="https://ieeexplore.ieee.org/document/5711470/" target="_blank">pdf</a>] <br />
    
<div id="abs_wifs10" style="text-align: justify; display: none">
        <p>Human metrology provides an important soft bio-metric, which can be used in challenging situations such as human identification at a distance, when traditional biometric traits such as fingerprints or iris cannot be easily acquired. We study the problem of predictability and correlation in human metrology, using the tools of uncertainty and differential entropy. We show that while various metrological features are highly correlated with each other, there exists some correlation clusters in human metrology, whereby measurements in a cluster tend to be highly correlated with each other but not with the others. Based on these clusters, we propose a two-step approach for predicting unknown body measurements. Using the same framework, we study the problem of estimating other soft biometrics such as weight and gender.</p>
      </div>

</td>
</tr>

</table>

<h3 id="journal-articles">Journal Articles</h3>
<!-- <a href="https://github.com/bamos/cv/blob/master/publications/journal.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a> -->

<table class="table table-hover">

<tr>
<td class="col-md-3"><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0166749" target="_blank"><img src="images/publications/journal.pone.png" /></a> </td>
<td>
    <strong>A Framework for Analyzing the Whole Body Surface Area from a Single View</strong><br />
    <strong>M. Piccirilli</strong>, G. Doretto, D.A. Adjeroh <br />
    PLOS One 2017<br />
    
    [J1] 
[<a href="javascript: none" onclick="$(&quot;#abs_pone&quot;).toggle()">abs</a>] [<a href="http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0166749&amp;type=printable" target="_blank">pdf</a>] <br />
    
<div id="abs_pone" style="text-align: justify; display: none">
        <p>We present a virtual reality (VR) framework for the analysis of whole human body surface area. Usual methods for determining the whole body surface area (WBSA) are based on well known formulae, characterized by large errors when the subject is obese, or belongs to certain subgroups. For these situations, we believe that a computer vision approach can overcome these problems and provide a better estimate of this important body indicator. Unfortunately, using machine learning techniques to design a computer vision system able to provide a new body indicator that goes beyond the use of only body weight and height, entails a long and expensive data acquisition process. A more viable solution is to use a dataset composed of virtual subjects. Generating a virtual dataset allowed us to build a population with different characteristics (obese, underweight, age, gender). However, synthetic data might differ from a real scenario, typical of the physician’s clinic. For this reason we develop a new virtual environment to facilitate the analysis of human subjects in 3D. This framework can simulate the acquisition process of a real camera, making it easy to analyze and to create training data for machine learning algorithms. With this virtual environment, we can easily simulate the real setup of a clinic, where a subject is standing in front of a camera, or may assume a different pose with respect to the camera. We use this newly designated environment to analyze the whole body surface area (WBSA). In particular, we show that we can obtain accurate WBSA estimations with just one view, virtually enabling the possibility to use inexpensive depth sensors (e.g., the Kinect) for large scale quantification of the WBSA from a single view 3D map.</p>
      </div>

</td>
</tr>



<tr>
<td class="col-md-3"><a href="https://www.researchgate.net/publication/287965460_A_Mobile_Structured_Light_System_for_3D_Face_Acquisition" target="_blank"><img src="images/publications/Marco_cropped.png" /></a> </td>
<td>
    <strong>A Mobile Structured Light System for 3D Face Acquisition</strong><br />
    <strong>M. Piccirilli</strong>, G. Doretto, A. Ross, D.A. Adjeroh <br />
    IEEE SENSORS JOURNAL Apr. 2016<br />
    
    [J2] 
[<a href="javascript: none" onclick="$(&quot;#abs_3d_mobile&quot;).toggle()">abs</a>] [<a href="https://www.researchgate.net/publication/287965460_A_Mobile_Structured_Light_System_for_3D_Face_Acquisition" target="_blank">pdf</a>] <br />
    
<div id="abs_3d_mobile" style="text-align: justify; display: none">
        <p>A mobile sensor based on fringe projection
techniques is developed with the goal of acquiring face 3D
and color with a smartphone device. The system consists of a
portable pico-projector and an Android-based smartphone. The
data acquisition, pattern generation. and reconstruction of the
final 3D point cloud are all driven by the smartphone. We present
results on the root-mean-square error (RMSE) of the sensor and
on 3D face matching.</p>
      </div>

</td>
</tr>

</table>

<!-- ### Workshop, Symposium, and Short Papers <a href="https://github.com/bamos/cv/blob/master/publications/short.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a> -->

<!-- <table class="table table-hover"> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>You can teach elephants to dance: agile VM handoff for edge computing</strong><br> -->
<!--     K. Ha, Y. Abe, T. Eiszler, Z. Chen, W. Hu, <strong>B. Amos</strong>, R. Upadhyaya, P. Pillai, and M. Satyanarayanan<br> -->
<!--     SEC 2017<br> -->

<!--     [W1]<br> -->

<!-- </td> -->
<!-- </tr> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>An Empirical Study of Latency in an Emerging Class of Edge Computing Applications for Wearable Cognitive Assistance</strong><br> -->
<!--     Z. Chen, W. Hu, J. Wang, S. Zhao, <strong>B. Amos</strong>, G. Wu, K. Ha, K. Elgazzar, P. Pillai, R. Klatzky, D. Siewiorek, and M. Satyanarayanan<br> -->
<!--     SEC 2017<br> -->

<!--     [W2]<br> -->

<!-- </td> -->
<!-- </tr> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>Quantifying the impact of edge computing on mobile applications</strong><br> -->
<!--     W. Hu, Y. Gao, K. Ha, J. Wang, <strong>B. Amos</strong>, Z. Chen, P. Pillai, and M. Satyanarayanan<br> -->
<!--     ACM SIGOPS 2016<br> -->

<!--     [W3]<br> -->

<!-- </td> -->
<!-- </tr> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>Privacy mediators: helping IoT cross the chasm</strong><br> -->
<!--     N. Davies, N. Taft, M. Satyanarayanan, S. Clinch, and <strong>B. Amos</strong><br> -->
<!--     HotMobile 2016<br> -->

<!--     [W4]  -->
<!-- [<a href='javascript: none' -->
<!--     onclick='$("#abs_davies2016privacyW").toggle()'>abs</a>] [<a href='http://eprints.lancs.ac.uk/78255/1/44691.pdf' target='_blank'>pdf</a>] <br> -->

<!-- <div id="abs_davies2016privacyW" style="text-align: justify; display: none" markdown="1"> -->
<!-- Unease over data privacy will retard consumer acceptance of IoT -->
<!-- deployments. The primary source of discomfort is a lack of user -->
<!-- control over raw data that is streamed directly from sensors to the -->
<!-- cloud. This is a direct consequence of the over-centralization of -->
<!-- today’s cloud-based IoT hub designs. We propose a solution that -->
<!-- interposes a locally-controlled software component called a privacy -->
<!-- mediator on every raw sensor stream. Each mediator is in the same -->
<!-- administrative domain as the sensors whose data is being collected, and dynamically enforces the current privacy policies of the owners -->
<!-- of the sensors or mobile users within the domain. This solution necessitates -->
<!-- a logical point of presence for mediators within the administrative -->
<!-- boundaries of each organization. Such points of presence -->
<!-- are provided by cloudlets, which are small locally-administered data -->
<!-- centers at the edge of the Internet that can support code mobility. -->
<!-- The use of cloudlet-based mediators aligns well with natural personal -->
<!-- and organizational boundaries of trust and responsibility. -->
<!-- </div> -->

<!-- </td> -->
<!-- </tr> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>Early Implementation Experience with Wearable Cognitive Assistance Applications</strong><br> -->
<!--     Z. Chen, L. Jiang, W. Hu, K. Ha, <strong>B. Amos</strong>, P. Pillai, A. Hauptmann, and M. Satyanarayanan<br> -->
<!--     WearSys 2015<br> -->

<!--     [W5]  -->
<!-- [<a href='javascript: none' -->
<!--     onclick='$("#abs_chen2015earlyW").toggle()'>abs</a>] [<a href='http://www.cs.cmu.edu/~satya/docdir/chen-wearsys2015.pdf' target='_blank'>pdf</a>] <br> -->

<!-- <div id="abs_chen2015earlyW" style="text-align: justify; display: none" markdown="1"> -->
<!-- A cognitive assistance application combines a wearable device such -->
<!-- as Google Glass with cloudlet processing to provide step-by-step -->
<!-- guidance on a complex task. In this paper, we focus on user assistance -->
<!-- for narrow and well-defined tasks that require specialized -->
<!-- knowledge and/or skills. We describe proof-of-concept implementations -->
<!-- for four different tasks: assembling 2D Lego models, freehand -->
<!-- sketching, playing ping-pong, and recommending context-relevant -->
<!-- YouTube tutorials. We then reflect on the difficulties we faced in -->
<!-- building these applications, and suggest future research that could -->
<!-- simplify the creation of similar applications. -->
<!-- </div> -->

<!-- </td> -->
<!-- </tr> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>The Case for Offload Shaping</strong><br> -->
<!--     W. Hu, <strong>B. Amos</strong>, Z. Chen, K. Ha, W. Richter, P. Pillai, B. Gilbert, J. Harkes, and M. Satyanarayanan<br> -->
<!--     HotMobile 2015<br> -->

<!--     [W6]  -->
<!-- [<a href='javascript: none' -->
<!--     onclick='$("#abs_hu2014caseW").toggle()'>abs</a>] [<a href='http://www.cs.cmu.edu/~satya/docdir/hu-hotmobile2015.pdf' target='_blank'>pdf</a>] <br> -->

<!-- <div id="abs_hu2014caseW" style="text-align: justify; display: none" markdown="1"> -->
<!-- When offloading computation from a mobile device, we show -->
<!-- that it can pay to perform additional on-device work in order -->
<!-- to reduce the offloading workload. We call this offload shaping, and demonstrate its application at many different levels -->
<!-- of abstraction using a variety of techniques. We show that -->
<!-- offload shaping can produce significant reduction in resource -->
<!-- demand, with little loss of application-level fidelity -->
<!-- </div> -->

<!-- </td> -->
<!-- </tr> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>Performance study of Spindle, a web analytics query engine implemented in Spark</strong><br> -->
<!--     <strong>B. Amos</strong> and D. Tompkins<br> -->
<!--     CloudCom 2014<br> -->

<!--     [W7]  -->
<!-- [<a href='javascript: none' -->
<!--     onclick='$("#abs_amos2014performanceW").toggle()'>abs</a>] [<a href='http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7037709' target='_blank'>pdf</a>]  [<a href='https://github.com/adobe-research/spindle' target='_blank'>code</a>] <br> -->

<!-- <div id="abs_amos2014performanceW" style="text-align: justify; display: none" markdown="1"> -->
<!-- This paper shares our experiences building and benchmarking Spindle as an open -->
<!-- source Spark-based web analytics platform. Spindle's design has been -->
<!-- motivated by real-world queries and data requiring concurrent, low latency -->
<!-- query execution. We identify a search space of Spark tuning options and study -->
<!-- their impact on Spark's performance. Results from a self-hosted six node -->
<!-- cluster with one week of analytics data (13.1GB) indicate tuning options such -->
<!-- as proper partitioning can cause a 5x performance improvement. -->
<!-- </div> -->

<!-- </td> -->
<!-- </tr> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>Global Parameter Estimation for a Eukaryotic Cell Cycle Model in Systems Biology</strong><br> -->
<!--     T. Andrew, <strong>B. Amos</strong>, D. Easterling, C. Oguz, W. Baumann, J. Tyson, and L. Watson<br> -->
<!--     SummerSim 2014<br> -->

<!--     [W8]  -->
<!-- [<a href='javascript: none' -->
<!--     onclick='$("#abs_andrew2014globalW").toggle()'>abs</a>] [<a href='http://dl.acm.org/citation.cfm?id=2685662' target='_blank'>pdf</a>] <br> -->

<!-- <div id="abs_andrew2014globalW" style="text-align: justify; display: none" markdown="1"> -->
<!-- The complicated process by which a yeast cell divides, known as the cell -->
<!-- cycle, has been modeled by a system of 26 nonlinear ordinary differential -->
<!-- equations (ODEs) with 149 parameters. This model captures the chemical -->
<!-- kinetics of the regulatory networks controlling the cell division process -->
<!-- in budding yeast cells. Empirical data is discrete and matched against -->
<!-- discrete inferences (e.g., whether a particular mutant cell lives or dies) -->
<!-- computed from the ODE solution trajectories. The problem of -->
<!-- estimating the ODE parameters to best fit the model to the data is a -->
<!-- 149-dimensional global optimization problem attacked by the deterministic -->
<!-- algorithm VTDIRECT95 and by the nondeterministic algorithms differential -->
<!-- evolution, QNSTOP, and simulated annealing, whose performances are -->
<!-- compared. -->
<!-- </div> -->

<!-- </td> -->
<!-- </tr> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>Fortran 95 implementation of QNSTOP for global and stochastic optimization</strong><br> -->
<!--     <strong>B. Amos</strong>, D. Easterling, L. Watson, B. Castle, M. Trosset, and W. Thacker<br> -->
<!--     SpringSim (HPC) 2014<br> -->

<!--     [W9]  -->
<!-- [<a href='javascript: none' -->
<!--     onclick='$("#abs_amos2014fortranW").toggle()'>abs</a>] [<a href='http://dl.acm.org/citation.cfm?id=2663525' target='_blank'>pdf</a>] <br> -->

<!-- <div id="abs_amos2014fortranW" style="text-align: justify; display: none" markdown="1"> -->
<!-- A serial Fortran 95 implementation of the QNSTOP algorithm is presented. -->
<!-- QNSTOP is a class of quasi-Newton methods for stochastic optimization with -->
<!-- variations for deterministic global optimization. This discussion provides -->
<!-- results from testing on various deterministic and stochastic optimization -->
<!-- functions. -->
<!-- </div> -->

<!-- </td> -->
<!-- </tr> -->

<!-- </table> -->

<!-- ### Magazine Articles <a href="https://github.com/bamos/cv/blob/master/publications/magazine.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a> -->

<!-- <table class="table table-hover"> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>Edge Analytics in the Internet of Things</strong><br> -->
<!--     M. Satyanarayanan, P. Simoens, Y. Xiao, P. Pillai, Z. Chen, K. Ha, W. Hu, and <strong>B. Amos</strong><br> -->
<!--     IEEE Pervasive Computing 2015<br> -->

<!--     [M1]  -->
<!-- [<a href='javascript: none' -->
<!--     onclick='$("#abs_satyanarayanan2015edgeM").toggle()'>abs</a>] [<a href='https://www.cs.cmu.edu/~satya/docdir/satya-edge2015.pdf' target='_blank'>pdf</a>] <br> -->

<!-- <div id="abs_satyanarayanan2015edgeM" style="text-align: justify; display: none" markdown="1"> -->
<!-- High-data-rate sensors, such as video cameras, are becoming ubiquitous in the -->
<!-- Internet of Things. This article describes GigaSight, an Internet-scale -->
<!-- repository of crowd-sourced video content, with strong enforcement of privacy -->
<!-- preferences and access controls. The GigaSight architecture is a federated -->
<!-- system of VM-based cloudlets that perform video analytics at the edge of the -->
<!-- Internet, thus reducing the demand for ingress bandwidth into the cloud. -->
<!-- Denaturing, which is an owner-specific reduction in fidelity of video content -->
<!-- to preserve privacy, is one form of analytics on cloudlets. Content-based -->
<!-- indexing for search is another form of cloudlet-based analytics. This article -->
<!-- is part of a special issue on smart spaces. -->
<!-- </div> -->

<!-- </td> -->
<!-- </tr> -->

<!-- <tr> -->
<!-- <td> -->
<!--     <strong>Bad Parts: Are Our Manufacturing Systems at Risk of Silent Cyberattacks?</strong><br> -->
<!--     H. Turner, J. White, J. Camelio, C. Williams, <strong>B. Amos</strong>, and R. Parker<br> -->
<!--     IEEE Security & Privacy 2015<br> -->

<!--     [M2]  -->
<!-- [<a href='javascript: none' -->
<!--     onclick='$("#abs_turner2015badM").toggle()'>abs</a>] [<a href='http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7118094' target='_blank'>pdf</a>] <br> -->

<!-- <div id="abs_turner2015badM" style="text-align: justify; display: none" markdown="1"> -->
<!-- Recent cyberattacks have highlighted the risk of physical equipment operating -->
<!-- outside designed tolerances to produce catastrophic failures. A related -->
<!-- threat is cyberattacks that change the design and manufacturing of a -->
<!-- machine's part, such as an automobile brake component, so it no longer -->
<!-- functions properly. These risks stem from the lack of cyber-physical models -->
<!-- to identify ongoing attacks as well as the lack of rigorous application of -->
<!-- known cybersecurity best practices. To protect manufacturing processes in the -->
<!-- future, research will be needed on a number of critical cyber-physical -->
<!-- manufacturing security topics. -->
<!-- </div> -->

<!-- </td> -->
<!-- </tr> -->

<!-- </table> -->

<h3 id="posters">Posters</h3>

<table class="table table-hover">

<tr>
<td>
    <strong>Unified Deep Supervised Domain Adaptation and Generalization</strong><br />
    Saeid Motiian, <strong>Marco Piccirilli</strong>, Donald A. Adjeroh, Gianfranco Doretto<br />
    ICCV 2017<br />
    
    [S1] [<a href="http://mpicci.github.io/data/posters/ICCV17.pdf" target="_blank">pdf</a>] <br />
    
</td>
</tr>


<tr>
<td>
    <strong>The beef with food recognition: a comparison of machine learning techniques</strong><br />
    Nathan Spencer, <strong>Marco Piccirilli</strong>, Don Adjeroh, Gianfranco Doretto<br />
    WVU SURE symposium 2015<br />
    
    [S2] [<a href="http://mpicci.github.io/data/posters/posterSymposium.pdf" target="_blank">pdf</a>] <br />
    
</td>
</tr>


</table>

<h2 id="i-classfa-fa-chevron-righti-recent-blog-posts"><i class="fa fa-chevron-right"></i> Recent Blog Posts</h2>

<table class="table table-hover">
  
    
    <tr>
      <td><a href="/2016/12/05/CPE691A/">Voice Verification of similar speech.</a></td>
      <td class="col-md-3" style="text-align: right;">December  5, 2016</td>
    </tr>
    
  
    
    <tr>
      <td><a href="/2014/06/05/3D_face/">A Mobile Structured Light System for 3D Face Acquisition</a></td>
      <td class="col-md-3" style="text-align: right;">June  5, 2014</td>
    </tr>
    
  
    
    <tr>
      <td><a href="/2013/06/06/BSA/">A framework to study the Human Body Surface Area</a></td>
      <td class="col-md-3" style="text-align: right;">June  6, 2013</td>
    </tr>
    
  
    
    <tr>
      <td><a href="/2012/12/12/Virtual-bodies/">A Virtual Dataset of Human Bodies</a></td>
      <td class="col-md-3" style="text-align: right;">December 12, 2012</td>
    </tr>
    
  
</table>
<h4><a href="/blog">View all</a></h4>

<!-- ## <i class="fa fa-chevron-right"></i> Fun Side Projects -->
<!-- + [CS conference tracker](https://github.com/bamos/conference-tracker). -->
<!-- + [SnowGlobe](https://github.com/bamos/snowglobe): -->
<!--   Haskell-driven, small-scale web analytics with minimal configuration. -->
<!-- + [My reading list](http://bamos.github.io/reading-list/): -->
<!--   YAML data and hosted on GitHub pages. -->
<!-- + [dotfiles](https://github.com/bamos/dotfiles): -->
<!--   &hearts; -->
<!--   [Arch Linux](https://www.archlinux.org/), -->
<!--   OSX, -->
<!--   [mutt](http://www.mutt.org/), -->
<!--   [xmonad](http://xmonad.org/), -->
<!--   [i3](https://i3wm.org/), -->
<!--   [vim](http://www.vim.org/), -->
<!--   [emacs](https://www.gnu.org/software/emacs/), -->
<!--   [zsh](http://www.zsh.org/), -->
<!--   [mpv](http://mpv.io/), -->
<!--   [cmus](https://cmus.github.io/). -->
<!-- + [girl](https://github.com/bamos/girl): -->
<!--   Scala program to find broken links in GitHub projects. -->
<!-- + [zsh-history-analysis](https://github.com/bamos/zsh-history-analysis): -->
<!--   Analyze shell usage patterns with Python and R. -->
<!-- + [python-scripts](https://github.com/bamos/python-scripts): -->
<!--   Short and fun Python scripts. -->
<!-- + [This website](https://github.com/bamos/bamos.github.io): -->
<!--   Built with Jekyll and hosted on GitHub pages. -->
<!-- + [cv](https://github.com/bamos/cv): -->
<!--   Python-driven resume-curriculum vitae with Jinja templates. -->
<!-- + [yaml-mailer](https://github.com/bamos/yaml-mailer): -->
<!--   Email many people different messages. -->
<!-- + [latex-templates](https://github.com/bamos/latex-templates) -->
<!--   and [beamer-snippets](https://github.com/bamos/beamer-snippets): -->
<!--   Personal collection and previewing of LaTeX and Beamer snippets. -->
<!--   Admittedly, I now use Keynote for presentations. -->

<hr />

<p>Last updated on 2019-01-28</p>


    </div>
  </div>
</div>


  <script src="/js/sp.js"></script>
  <script src="/vendor/js/jquery.min.js"></script>
  <script src="/vendor/js/bootstrap.min.js"></script>
  <script src="/vendor/js/anchor.min.js"></script>
  <script src="/vendor/js/jquery.toc.js"></script>
  <script type="text/javascript">
   try {
       var snowplowTracker = Snowplow.getTrackerUrl('joule.isr.cs.cmu.edu:8081');
       snowplowTracker.enableLinkTracking();
       snowplowTracker.trackPageView();
   } catch (err) {}

   (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
   (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
   m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
   })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

   ga('create', 'UA-102191838-1', 'auto');
   ga('send', 'pageview');

   $("#toc").toc({
       'headings': 'h2,h3'
   });
   anchors.add('h2,h3');
  </script>

</body>

</html>
